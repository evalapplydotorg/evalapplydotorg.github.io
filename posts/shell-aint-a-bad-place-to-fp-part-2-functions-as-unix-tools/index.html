<!doctype html><html lang=en prefix="og: https://ogp.me/ns#"><title>Shell ain't a bad place to FP: part 2/N: Functions as Unix Tools</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Aditya Athalye"><meta name=description content="Or, the one in which we hand-craft nano Unix tools using Bash functions."><meta name=keywords content="systems thinking,functional programming,architecture,software design,technology leadership,devops,clojure"><meta property="og:title" content="Shell ain't a bad place to FP: part 2/N: Functions as Unix Tools"><meta property="og:description" content="Or, the one in which we hand-craft nano Unix tools using Bash functions."><meta property="og:locale" content="en_GB"><meta property="og:type" content="website"><meta property="og:url" content="https://www.evalapply.org/posts/shell-aint-a-bad-place-to-fp-part-2-functions-as-unix-tools/index.html"><link rel="stylesheet preload" as=style href=https://www.evalapply.org/static/css/style.css><link href=https://www.evalapply.org/index.xml rel=alternate type=application/rss+xml title="Eval / Apply is pure magic"><link rel=canonical href=https://www.evalapply.org/posts/shell-aint-a-bad-place-to-fp-part-2-functions-as-unix-tools/index.html><link rel=icon type=image/vnd.microsoft.icon href=https://www.evalapply.org/static/img/favicon.ico><div id=the-very-top class="stack center box"><header id=site-header><div class="box invert stack"><div class="with-sidebar site-header"><a class="box icon" href=https://www.evalapply.org/index.html><img src=https://www.evalapply.org/static/img/Lisp_logo.svg alt="Eval / Apply is pure magic"></a><div class=stack><h1 class="site-header title">Eval / Apply is pure magic</h1><nav class="cluster site-header site-header:nav-items"><a href=https://www.evalapply.org/index.html>&#955; hello</a>
<a href=https://www.evalapply.org/posts/index.html>&#9753; read</a>
<a href=mailto:hello@evalapply.org>&nbsp;&#9993; write</a>
<a href=https://www.evalapply.org/now.html#main>&#171; now &#187;</a>
<a href=https://www.evalapply.org/index.xml>&ap; feed</a></nav></div></div></div></header><main id=main><article id=blog-post class=stack><header><div class=stack><div class=title>Shell ain't a bad place to FP: part 2/N: Functions as Unix Tools</div><div class="cluster post-meta"><span>&uarr; <a href=#site-header rel=bookmark>menu</a></span>
<span>&darr; <a href=#blog-post-footer rel=bookmark>discuss</a></span>
<span>&darr; <a href=#blog-post-toc rel=bookmark>toc</a></span></div><div class=summary>Or, the one in which we hand-craft nano Unix tools using Bash functions.</div><div class="cluster post-meta"><span class=author>By: Adi</span>
<span class=date>Published: 2022-04-27</span>
<span class=date>Updated: 2022-04-27</span>
<span class=tags>Tags: / <a href=https://www.evalapply.org/tags/bash/index.html#main>#bash</a> / <a href=https://www.evalapply.org/tags/unix/index.html#main>#unix</a> / <a href=https://www.evalapply.org/tags/functional_programming/index.html#main>#functional_programming</a> / <a href=https://www.evalapply.org/tags/architecture/index.html#main>#architecture</a></span></div><hr></div></header><section class=stack><div id=blog-post-toc class="stack table-of-contents"><details class="box invert stack" open><summary><strong>Contents</strong></summary><nav class=stack><a href=#previously-in-this-series class=toc-heading:h1>Previously in this series…</a>
<a href=#what-bash-functions-are class=toc-heading:h1>What Bash functions are</a>
<a href=#bash-functions-are-compound-commands class=toc-heading:h2>Bash functions are compound commands</a>
<a href=#function-definitions-live-in-a-global-namespace class=toc-heading:h2>Function definitions live in a global namespace</a>
<a href=#how-to-design-good-functions class=toc-heading:h1>How to design good functions</a>
<a href=#wrap-domain-concepts-in-single-purpose-functions class=toc-heading:h2>Wrap domain concepts in single-purpose functions</a>
<a href=#use-parameter-substitutions-and-local-scope-variables class=toc-heading:h2>Use parameter substitutions and local scope variables</a>
<a href=#partial-application-of-functions class=toc-heading:h2>Partial application of functions</a>
<a href=#dependency-injection-with-functions class=toc-heading:h2>Dependency injection with functions</a>
<a href=#keeping-functions-pure class=toc-heading:h2>Keeping Functions pure</a>
<a href=#program-design-with-functions class=toc-heading:h1>Program design with functions</a>
<a href=#writing-pipeline-friendly-functions class=toc-heading:h2>Writing Pipeline-friendly Functions</a>
<a href=#separating-return-values-and-non-values class=toc-heading:h2>Separating return values and non-values</a>
<a href=#functions-to-delay-evaluation class=toc-heading:h2>Functions to delay evaluation</a>
<a href=#functional-core-imperative-shell class=toc-heading:h2>Functional core, imperative shell</a>
<a href=#naming-conventions class=toc-heading:h1>Naming conventions</a></nav></details></div><hr><p>As we saw in the <a href=https://evalapply.org/posts/shell-aint-a-bad-place-to-fp-part-1-doug-mcilroys-pipeline>previous post</a>, functions obey stdio and we can mix and match them with built-ins (grep, sed, cat etc.) and other installed tools (like jq, pandoc, babashka etc.). We used functions to name parts of Douglas McIlroy's pipeline and mess around a bit.<p>I tend to make libraries of pure functions that I can source in shell sessions and use just like any other shell tool, complete with tab-completion. e.g. <a href=https://github.com/adityaathalye/bash-toolkit>bash-toolkit</a> and <a href=https://github.com/adityaathalye/shite>shite</a>.<p>Now we step back and try to build good intuitions about<ul><li>what functions are<li>how to design good functions<li>how to design programs with functions<li>how to name them :)</ul><h1 id=previously-in-this-series>Previously in this series…</h1><ul><li><a href=https://evalapply.org/posts/shell-aint-a-bad-place-to-fp-part-1-doug-mcilroys-pipeline>Part 1/N</a>: Exploring McIlroy's pipeline to motivate the series. And an unexpected masterclass from the Master himself (see appendix)!<li><a href=https://evalapply.org/posts/shell-aint-a-bad-place-to-fp-part-0-intro/>Part 0/N</a>: intro, caveats, preamble</ul><h1 id=what-bash-functions-are>What Bash functions are</h1><p>Last time, we wrote functions like this:<pre class=shell><code>flatten_paragraphs() {
    tr -cs A-Za-z &#39;\n&#39;
}
</code></pre><p>The syntax may look familiar, but their behaviour and semantics differ in many ways from functions in the more modern languages like Python or JS etc.<h2 id=bash-functions-are-compound-commands>Bash functions are compound commands</h2><p><code>man bash</code> describes functions as follows (online manpage: <a href=https://www.gnu.org/software/bash/manual/html_node/Shell-Functions.html>shell functions</a>).<blockquote><p><strong>Shell Function Definitions</strong><p>A shell function is an object that is called like a simple command and executes a compound command with a new set of positional parameters. Shell functions are declared as follows:<p><code>name () compound-command [redirection]</code><p>… and more stuff …</blockquote><p>We will do names last, because names are hard :) Let's start with the "compound command" part.<p>There are several ways to write <em>compound commands</em>, each serving a different purpose. To define functions, we only need the <code>{ list; }</code> form. So we will ignore the others. Some context from the Bash manpage.<blockquote><p><strong>Compound Commands</strong><p>A compound command is one of the following. In most cases a list in a command's description may be separated from the rest of the command by one or more newlines, and may be followed by a newline in place of a semicolon.<p><code>(list)</code> list is executed in a subshell environment …<p><code>{ list; }</code> list is simply executed in the current shell environment. list must be terminated with a newline or semicolon. This is known as a group command. The return status is the exit status of list. Note that unlike the metacharacters ( and ), { and } are reserved words and must occur where a reserved word is permitted to be recognized. Since they do not cause a word break, they must be separated from list by whitespace or another shell metacharacter.<p><code>((expression))</code> Arithmetic expressions …<p><code>[[ expression ]]</code> Compound conditional expression …</blockquote><p>The Bash manual page can feel a little obtuse at times. Hopefully the examples and discussion in this post will serve as useful illustrations.<h2 id=function-definitions-live-in-a-global-namespace>Function definitions live in a global namespace</h2><p>This means function definitions are isolated, and don't override any alias, builtin, variable, or reserved keyword of the same name.<p>To see what that means, let's bind the same name to different things.<pre class=shell><code>$ sed() { echo lol; } # will the function override the sed built-in?

$ sed=&quot;phew!&quot; # will the variable override the function we defined?

$ alias sed=cat # will the alias override everything?
</code></pre><p>We can query all objects that the name <code>sed</code> is bound to. (Note: the variable meaning won't show up in this listing.)<pre class=shell><code>$ type -a sed
sed is aliased to &#39;cat&#39;
sed is a function
sed ()
{
    echo lol
}
sed is /bin/sed
</code></pre><p>And we can invoke or evaluate each meaning of the word <code>sed</code>.<pre class=shell><code>$ man bash | sed # Oops. Boy, are we in trouble now.
# Bash interprets the unquoted word as an alias, which is &#39;cat&#39;.

$ man bash | command sed 1q # execute as a command (not function, or alias)
BASH(1)           General Commands Manual              BASH(1)


$ &#39;sed&#39; # quoting prevents interpretation as alias. Function meaning gets used.
lol

$ echo foo | &#39;sed&#39; # works fine in pipes too
lol

$ echo $sed # the variable remains intact too
phew!
</code></pre><p>This namespacing is certainly merciful, but it is not quite enough. As you may have guessed, it can get very confusing if we reuse names willy-nilly. If there was one thing I could improve about Bash, it would be adding "real" namespaces. That would help write modular code. Alas, that ship sailed long ago.<p>Anyway, I drop Bash after the code starts getting too involved; beyond about 1,000 LoC (of clean FP-style Bash). In large scripts, the sharp corners of Ye Olde Shell start poking holes and forcing bugs (quoting, expansion, trap/error handling etc.).<p>That said (or um, sed), under 1K LoC clean FP-style Bash can do a crazy amount of work sufficiently fast <a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a>. That sweet spot is what this series is all about. Like <a href=https://github.com/adityaathalye/shite>shite</a> and <a href=https://github.com/adityaathalye/oxo>oxo</a>.<h1 id=how-to-design-good-functions>How to design good functions</h1><p>Bash functions provide certain highly functional features like obeying stdio, thus being streaming-friendly units of program design. Several other creature comforts of functional style are not automatic. <em>However</em> we can get plenty functional with <em>some</em> care and manual effort.<p>Here are things I do to keep my functions, well, functional.<h2 id=wrap-domain-concepts-in-single-purpose-functions>Wrap domain concepts in single-purpose functions</h2><p>Previously, we wrapped invocations of Unix tools and pipelines in functions, gave them domain-specific names, to achieve domain-specific compositional power.<p>For example:<pre class=shell><code>sort_dictionary() {
    sort -b -d -k2
}

sort_rhyme() {
    rev | sort -b -d | rev
}
</code></pre><p>Small functions are absolutely fine! In fact, we prefer our functions be small, single-purpose, and as general as possible, just like any other Unix tool.<h2 id=use-parameter-substitutions-and-local-scope-variables>Use parameter substitutions and local scope variables</h2><p>Functions only accept positional parameters, like regular shell scripts. And like regular scripts, we can send input for evaluation as well as to control behaviour of the function, as well will see later in this post.<p>Unfortunately, positional-only params make optionality hard. The following techniques help mitigate this limitation. Compare them with the example below.<ul><li>I tend to keep my functions small and avoid API design that requires more than 3 parameters. This is just a nonscientific thumb rule.<li>Next, I use Bash parameter substitution to provide sane fallbacks, and/or enforce API contracts (fail and die if param not provided).<li>I always assign positional params to local variables inside the function body, which is a bit verbose, but improves readability and traceability. And it makes any parameter substitution explicit.<li>I also declare all named params as <code>local</code>, which ensures variable scope and mutation is local to the function.</ul><p>Most of my parameter-accepting functions are designed with just one optional parameter. Here is a motivating example from my little <a href=https://github.com/adityaathalye/bash-toolkit>bash-toolkit</a> library. The ones copied here help with ad-hoc log analysis tasks.<p>Accept optional parameter, with a sane default.<pre class=shell><code>drop_first_n() {
    local lines=&quot;${1:-0}&quot;
    local offset=&quot;$(( lines + 1 ))&quot;

    tail -n +&quot;${offset}&quot;
}

drop_last_n() {
    local lines=&quot;${1:-0}&quot;
    head -n -&quot;${lines}&quot;
}
</code></pre><p>Enforce all parameters, as these functions are meaningless without them.<pre class=shell><code>drop_header_footer() {
    local header_lines=&quot;${1:?&#39;FAIL. Header line count required, 1-indexed.&#39;}&quot;
    local footer_lines=&quot;${2:?&#39;FAIL. Footer line count required, 1-indexed.&#39;}&quot;

    drop_first_n &quot;${header_lines}&quot; |
        drop_last_n &quot;${footer_lines}&quot;
}

window_from_to_lines() {
    local from_line=&quot;${1:?&#39;FAIL. \&quot;FROM\&quot; line number required, 1-indexed.&#39;}&quot;
    local to_line=&quot;${2:?&#39;FAIL. \&quot;TO\&quot; line number required, 1-indexed.&#39;}&quot;

    drop_first_n &quot;${from_line}&quot; |
        head -n &quot;${to_line}&quot;
}
</code></pre><p>Notice how the latter two functions reuse the earlier functions to create completely different log processing tools, yet retain flexibility to deal with arbitrary parts of log files, as well as compose together any way we please (not all of which will be sensible, but that's besides the point :).<p>There are many ways to do <a href=https://wiki.bash-hackers.org/scripting/posparams>parameter handling</a>; a whole topic of its own. Play around to get a sense for it, but keep your actual usage simple.<h2 id=partial-application-of-functions>Partial application of functions</h2><p><a href=https://en.wikipedia.org/wiki/Partial_application>Partial application</a> is not automatic in Bash, but that does not mean we can't do it.<p>In the example below, a utility function <code>__with_git_dir</code> knows something about a git directory, but nothing about a git subcommand that we wish to run.<pre class=shell><code>__with_git_dir() {
    local repo_dir=&quot;${1}&quot;
    shift
    git --git-dir=&quot;${repo_dir}/.git&quot; &quot;$@&quot;
}

git_fetch() {
    local repo_dir=&quot;${1}&quot;
    __with_git_dir &quot;${repo_dir}&quot; fetch -q
}

git_status() {
    __with_git_dir &quot;${1}&quot; status
}

git_branch_current() {
    local repo_dir=&quot;${1}&quot;
    __with_git_dir &quot;${repo_dir}&quot; rev-parse --abbrev-ref=strict HEAD
}
</code></pre><p>These functions <a href=https://github.com/adityaathalye/bash-toolkit/blob/7cbac8bd6a7970481f6f62e5a2a604afcaf804ea/bulk-git-ops.sh#L99>belong to some git utilities</a> <a href=#fn2 class=footnote-ref id=fnref2 role=doc-noteref><sup>2</sup></a> that help me conveniently run git commands against any repo on my file system, without cd-ing to the repo.<p>See? Functions can be dead-simple yet super useful. If you accumulate wee functions for your git needs, you get executable documentation. You can <code>source</code> them in your Bash terminal on any computer and be on your way. Likewise, any other command-line-y need of yours.<h2 id=dependency-injection-with-functions>Dependency injection with functions</h2><p>The previous section brought us close to dependency injection. We passed in git subcommands as argument to the <code>__with_git_dir</code> utility. <em><strong>We can do the same with our own functions.</strong></em> This is a form of "higher order" Functional Programming; viz. making functions that accept functions as arguments.<p>For example, <a href=https://github.com/adityaathalye/bash-toolkit/blob/7cbac8bd6a7970481f6f62e5a2a604afcaf804ea/bulk-git-ops.sh>see the same git utilities file</a> for usages such as these:<ul><li><p>Use the <code>xgit</code> utility fn to apply simple git commands to the given repos.<pre class=shell><code>ls_git_projects ~/src/bitbucket | xgit fetch # bitbucket-hosted repos
</code></pre><li><p>Use <code>proc_repos</code> to apply custom functions to the given repos.<pre class=shell><code>ls_git_projects ~/src/bitbucket |
    proc_repos git_fetch # all repos

ls_git_projects ~/src/bitbucket |
    take_stale |
    proc_repos git_fetch # only stale repos

ls_git_projects ~/src/bitbucket |
    take_active |
    proc_repos git_fetch # only active repos
</code></pre><li><p>What's the current branch?<pre class=shell><code>ls_git_projects ~/src/bitbucket |
    proc_repos git_branch_current
</code></pre></ul><p>I've also used this design technique in <a href=https://github.com/adityaathalye/shite>shite</a> (the little static site generator from shell :). This is baaasically what its <a href=https://github.com/adityaathalye/shite/blob/f8d2d22316a8c2fc04c92c1390abb77c69377f6f/shite_utils.sh#L237>"main" function</a> does.<pre class=shell><code># Build page and tee it into the public directory, namespaced by the slug
cat ${body_content_file} |
    ${content_proc_fn} |
    # We have only one page builder today, but
    # we could have a variable number tomorrow.
    shite_build_page  |
    ${html_formatter_fn} |
    tee &quot;${shite_global_data[publish_dir]}/${html_output_file_name}&quot;
</code></pre><p>All the <code>_fn</code>-suffixed variables are locals in the "main" fn, that are assigned to function names we pass from the outside. Also notice the use of sane fallbacks for the positional params in this case.<h2 id=keeping-functions-pure>Keeping Functions pure</h2><p>The <code>return</code> statement in Bash returns exit codes, not values. So we have to pause a bit to figure out how to "return" values. Well, we have to rely on stdio, and the fact that the Unix tools philosophy encourages us to emit data in the same format as we receive it.<p>The <code>identity</code> function is the simplest example. By definition, it returns its input unchanged. That's just <code>cat</code>! Thus we can write this streaming <em>identity</em> function.<pre class=shell><code>identity() {
    cat -
}
</code></pre><p>This definition of <em>identity</em> is surprisingly useful, as we will see below.<p>Note that I strongly favour pipeline-friendly domain modeling and functional programming, to profit from the naturally streaming nature of Unix.<p>Under such architecture, <em>map</em>, <em>filter</em>, and <em>reduce</em> are automatic, and I only need to write a pure "step" or single-item processing function.<p>My "step" functions are simply transforms of input text (or data structure) to output text (or data structure). This can be anything; in case of plain text lines I do line transforms with <code>sed</code> or <code>printf</code>, or line selects with <code>grep</code>, or line-munging with <code>tr</code> etc. I do the equivalent with <code>jq</code> for JSON-formatted lines. <a href=http://evalapply.org/posts/shell-aint-a-bad-place-to-fp-part-1-doug-mcilroys-pipeline/>The previous post</a> featured such "step" functions for <em>map</em> (<code>tokenise_lowercase</code>, <code>bigram</code>), <em>filter</em> (<code>drop_stopwords</code>), and <em>reduce</em> (<code>frequencies</code>, <code>sort_dictionary</code>).<p><em>shite</em> has a <a href=https://github.com/adityaathalye/shite/blob/f8d2d22316a8c2fc04c92c1390abb77c69377f6f/shite_utils.sh#L89>more interesting example</a>.<p>Suppose we want to make a blog site. For each blog post, only the content changes. The surrounding HTML wrapper remains constant (head, body, header, footer etc.). If we tease apart wrapper HTML construction and body HTML construction, then we can write a "page builder" function like this. Note the <code>cat -</code> in the middle. Our identity function appears!<pre class=shell><code>shite_build_page() {
    cat &lt;&lt;EOF
&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;!-- Some basic hygiene meta-data --&gt;
        &lt;meta charset=&quot;utf-8&quot;&gt;
        &lt;title&gt;My Blog&lt;/title&gt;
        &lt;link rel=&quot;stylesheet&quot; href=&quot;css/style.css&quot;&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;header id=&quot;site-header&quot;&gt;
          &lt;h1&gt;My Blog&lt;/h1&gt;
          &lt;hr&gt;
        &lt;/header&gt;
        &lt;main&gt;
          $(cat -)
        &lt;/main&gt;
        &lt;footer&gt;
          &lt;hr&gt;
          &lt;p&gt;All content is MIT licensed, except where specified otherwise.&lt;/p&gt;
        &lt;/footer&gt;
    &lt;/body&gt;
&lt;/html&gt;
EOF
}
</code></pre><p>Observe that <code>$(cat -)</code> blindly injects content in the <code>&lt;main>&lt;/main></code> block, received via stdin of the <em>function</em> <code>shite_build_page</code>. Thus, for the same input it will always produce the same output, making it a pure function. This choice also makes the caller responsible for passing it HTML, because the output is HTML.<p>Further, by the single responsibility principle, our function's job is simply to punch HTML content into an HTML wrapper and return the composite. So it is vital that this function <em>not know or care</em> how the HTML it receives is made.<p>And here's the cherry… By making this design choice, we have in fact made a step function that we can <em>map</em> over many blog posts.<pre class=shell><code>gen_html_posts_from_md() {
    while read blog_post_md_file
    do local html_file_name=&quot;$(basename -s.md ${blog_post_md_file}).html&quot;
       pandoc -f markdown -t html ${html_file_name} |
           shite_build_page &gt; ./public/posts/${html_file_name}
    done
}
</code></pre><p>Thus, if our blog posts are <code>markdown</code> files in some folder (let's say under a <code>content</code> directory). We can do this.<pre class=shell><code>find ./content/posts/ -type f -name *.md |
    gen_html_posts_from_md
</code></pre><p>A reader may complain that our HTML posts generator function is too specific to the markdown format, and knows too much about how to transform markdown to HTML, as well as where to put it. Its job ought to be just to describe the transform process.<p>The reader would be right, and may like to solve the problem at home <a href=#fn3 class=footnote-ref id=fnref3 role=doc-noteref><sup>3</sup></a> :)<h1 id=program-design-with-functions>Program design with functions</h1><p>Now, how do we apply functional programming principles to the next level up, viz. to design our programs?<p>If you've seen shell scripts in the wild, you'd have observed they are often written as sequences of statements and imperative control flow that evaluates top to bottom. I think that practice is a bit tragic, because it produces needlessly complex code, because people reach for flags and global variables and traps and suchlike.<p>Functions obviate a lot of that icky stuff. We still need the ick, but we can constrain it to very specific tightly controlled bits of our program, and only when the ick makes absolute sense.<p>I will also say that if we can make programs that are themselves functional compositions, then we can chain entire programs together into still larger scale functional structures. Further, since stdio includes named pipes, and sockets, we can compose multi-process as well as multi-machine pipelines, with a great economy of code. And this is <em>not</em> insane at all. Seriously.<p>But I'm getting ahead of myself. Here is how I try to keep my programs functional.<h2 id=writing-pipeline-friendly-functions>Writing Pipeline-friendly Functions</h2><p>Frequently, an imperative algorithm can also be expressed in data-flow terms. That is, instead of if-else-y code, think in terms of map/filter/reduce.<p>Once again, recalling the git utility functions referenced above. Suppose you had to return a list of "stale" repositories from a given directory, you may be tempted to write something like this. (Here "stale" means "not worked on for the last N hours").<pre class=shell><code>get_stale_repos() {
    local repos_root_dir=&quot;${1}&quot;
    local stale_hrs=&quot;${2:-12}&quot;
    local hrs_ago=$(( ($(date +%s)
                       - $(stat -c %Y &quot;${repo_dir}/.git&quot;))
                      / 3600 ))

    for repo_dir in $(ls ${repos_root_dir}); do
        if [[ $hrs_ago -le $stale_hrs ]]
        then printf &quot;%s\n&quot; &quot;active: ${repo_dir}&quot;
        else printf &quot;%s\n&quot; &quot;stale: ${repo_dir}&quot;
        fi
    done
}
</code></pre><p>However this kind of implementation combines ("complects") many different things.<p>Given the fact that functions respect <code>stdio</code>, we can pull apart our imperative attempt. The insight is to combine <code>while</code> and <code>read</code> as follows. I use this idiom a lot because it helps me drastically simplify my code.<pre class=shell><code>__is_repo_active() {
    local repo_dir=&quot;${1}&quot;
    local stale_hrs=&quot;${2:-12}&quot;
    local hrs_ago=$(( ($(date +%s)
                       - $(stat -c %Y &quot;${repo_dir}/.git&quot;))
                      / 3600 ))
    [[ $hrs_ago -le $stale_hrs ]]
}

take_stale() {
    local repo_dir
    while read repo_dir
    do __is_repo_active &quot;${repo_dir}&quot; || printf &quot;%s\n&quot; &quot;${repo_dir}&quot;
    done
}
</code></pre><p>Now we can do this:<pre class=shell><code>ls ~/src/github/adityaathalye |
    take_stale
</code></pre><p>And we get bonus reuse, because we may also want to do the inverse.<pre class=shell><code>take_active() {
    local repo_dir
    while read repo_dir
    do __is_repo_active &quot;${repo_dir}&quot; &amp;&amp; printf &quot;%s\n&quot; &quot;${repo_dir}&quot;
    done
}
</code></pre><p>With a little bit more thinking, we can pull apart this logic even further, usefully. Hint: these functions have a <code>filter</code> embedded inside them.<p>As another fun example, one <span class=citation data-cites=rsms>@rsms</span> <a href=https://twitter.com/rsms/status/1508900257324666882>tweeted this</a> recently:<blockquote><p>Was curious about source code-line length so wrote a horribly hacky bash script that draws a histogram. <a href=https://gist.github.com/rsms/36bda3b5c8ab83d951e45ed788a184f4>https://gist.github.com/rsms/36bda3b5c8ab83d951e45ed788a184f4</a></blockquote><p>I saw the script and my habitual thought kicked in, "Well, why can't that be a pipeline?". A short while later, this emerged.<pre class=shell><code># get some lines of text
man bash |
    # remove blank lines (extensible to any non-code lines)
    grep -v &#39;^$&#39; |
    # count chars for each line
    while read line; do echo ${line} | wc -c - | cut -d&#39; &#39; -f1; done |
    # calculate the frequency distribution
    sort -nr | uniq -c |
    # add a histogram graph to the frequency distribution
    while read lines cols;
    do printf &quot;%s\t%s\t%s\n&quot; ${lines} ${cols} $(printf &quot;%0.s|&quot; $(seq 1 8 ${cols}));
    done |
    # add labels to the histogram
    cat &lt;(printf &quot;%s\t%s\t%s\n&quot; &quot;LN&quot; &quot;COL&quot; &quot;HIST(|=8COL)&quot;) -
</code></pre><p>Note the similarities to McIlroy's pipeline from the last post. Also, like that program, mine too fits in a tweet and I wasn't even trying.<h2 id=separating-return-values-and-non-values>Separating return values and non-values</h2><p>"Don't be chatty" is an important design principle. This means don't pollute your stdout values with non-values. Sometimes though, we want to emit process information (like logs) <em>along</em> with emitting process output. For example, a structured process log becomes handy when we want to design idempotent jobs.<p>Going back to my <a href=https://github.com/adityaathalye/bash-toolkit/blob/7cbac8bd6a7970481f6f62e5a2a604afcaf804ea/bulk-git-ops.sh#L49>bulk-git-ops example</a>, suppose I want to process a whole bunch of git repos. This may fail any time if my network flakes, or laptop battery dies, or some weird condition occurs. Sh*t happens when processes run for a long time <em>and</em> need networks. So I usually want to log each repo as it is being processed.<pre class=shell><code>identity() {
    printf &quot;%s\n&quot; &quot;$@&quot;
}

proc_repos() {
    # Apply any given operation on the given repos. Use in a pipeline.
    # Presumably, the supplied function emits values expected by stdin
    # of the downstream function.
    local func=${1:-identity}
    local repo_dir
    while read repo_dir
    do $func &quot;${repo_dir}&quot;
       log_info &quot;Applied ${func} to ${repo_dir}&quot;
    done
}
</code></pre><p>This way a downstream consumer can rely on always receiving a legal value at stdin, and <em>optionally</em> access non-values (like logs), if it wants to, via stderr <a href=#fn4 class=footnote-ref id=fnref4 role=doc-noteref><sup>4</sup></a>.<p>I casually name-dropped <em>idempotence</em>. It needs its own blog post. Maybe the next one!<h2 id=functions-to-delay-evaluation>Functions to delay evaluation</h2><p>I like to write my code in groups and sequences that help a reader acquire context easily, and I call it in sequences that make sense from a process point of view. Functions help me do this, because they group statements in the scope of the script, <em>without</em> causing the interpreter to evaluate them.<p>For example, scripts I wrote:<ul><li>to <a href=https://gitlab.com/nilenso/cats/-/blob/c26bcd7e6618843690070b8bf38cf7adb553a0d2/bin/cicd-deployment.sh#L122>perform build/deploy steps</a> for a study project<li>to help me <a href=https://github.com/adityaathalye/bash-toolkit/blob/7cbac8bd6a7970481f6f62e5a2a604afcaf804ea/machine-setup.sh#L274>set up my machine</a> (or at least remember what I have use for :)</ul><h2 id=functional-core-imperative-shell>Functional core, imperative shell</h2><p>Pun intended. This is <a href=https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell>a very useful design technique</a>.<p>We lift out as much work as possible into lots of small, pure, single purpose functions, and compose these separately to do composite work and/or to cause effects (perform I/O, set/reset globals, mutate in-process state etc.).<p>You may observe it applied in all my code:<ul><li>My <a href=https://github.com/adityaathalye/bash-toolkit/blob/7cbac8bd6a7970481f6f62e5a2a604afcaf804ea/usage-trap.sh#L109>usage-trap file</a> is a template for how I tend to go about that for single-file scripts.<li>The whole game design of <a href=https://github.com/adityaathalye/oxo>oxo</a>:<ul><li>The <code>oxo_logic.sh</code> file is the "functional core".<li>The <code>oxo</code> file is the "imperative shell" (and is the game's entry point).</ul><li><a href=https://github.com/adityaathalye/shite>shite</a> is being developed exactly this way.</ul><p>This technique helps me develop scripts incrementally, in terms of highly reusable, testable, composable functional "lego blocks".<h1 id=naming-conventions>Naming conventions</h1><p>Now the really hard part…<p>I write all my function names as follows, because it is the most portable syntax. Bash accepts several ways to define functions, but POSIX sh strictly expects this syntax, and I prefer to maintain as much compatibility as I can. Also I find it is the neatest of the alternatives.<pre class=shell><code>namespace_func_name() {
    statement 1
    statement 2
    statement 3
}
</code></pre><p>Sometimes I write short one-liners as follows. The semicolon is essential for one-liners. So is the space between the braces and the statement.<pre class=shell><code>namespace_func_name() { statement ; }
</code></pre><p>There is no such thing as a "private" or locally-scoped function, so I resort to marking these "private" by convention with a <code>__</code> (double underscore) prefix.<pre class=shell><code>__namespace_private_func_name() {
    statement1
    statement2
}
</code></pre><p>The following syntax is legal Bash, but I do not use it.<pre class=shell><code>function namespace_func_name {
    statement1
    statement2
}

function namespace_func_name() {
    statement1
    statement2
}

# OR one-liner variants
function namespace_func_name { statement ; }
function namespace_func_name() { statement ; }

</code></pre><p>Bash accepts <code>.</code> and <code>-</code> in function names, but that is also a no-no for me. A linter like Shellcheck will complain in strict mode.<pre class=shell><code>namespace.funcname() {
    statement 1
    statement 2
}

namespace-funcname() {
    statement 1
    statement 2
}
</code></pre><p>Ok, we covered a lot of ground, so I'll stop for now. There are more aspects of FP in bash (idempotence, declarative programming etc.), for future posts. But even this much will elevate your shell-fu, and let you write nontrivial scripts incrementally, safely, and maintainably.<p>Happy Bash-ing!<section class=footnotes role=doc-endnotes><hr><ol><li id=fn1 role=doc-endnote><p>And if you use awk, I hear that it is known to outperform hand optimized C for a variety of data processing problems. Apparently genomics people awk a lot.<a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a><li id=fn2 role=doc-endnote><p>You may particularly enjoy those if you sometimes (or often) have to do bulk maintenance on many repos. Fetch and update them, or at least identify stale repos before deciding what to do etc.<a href=#fnref2 class=footnote-back role=doc-backlink>↩︎</a><li id=fn3 role=doc-endnote><p>Hint: Partial application and/or dependency injection may be appropriate.<a href=#fnref3 class=footnote-back role=doc-backlink>↩︎</a><li id=fn4 role=doc-endnote><p>Monads. There, I said it.<a href=#fnref4 class=footnote-back role=doc-backlink>↩︎</a></ol></section></section><footer id=blog-post-footer class="footer stack"><nav class=cluster><span>&uarr; <a href=#blog-post rel=bookmark>title</a></span>
<span>&uarr; <a href=#site-header rel=bookmark>menu</a></span>
<span><b>Y</b> <a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fwww.evalapply.org%2Fposts%2Fshell-aint-a-bad-place-to-fp-part-2-functions-as-unix-tools%2Findex.html&t=Shell%20ain't%20a%20bad%20place%20to%20FP%3A%20part%202%2FN%3A%20Functions%20as%20Unix%20Tools">discuss at HN</a></span>
<span>&rarr; <a href=mailto:weblog@evalapply.org>email comments</a></span>
<span><a class=site-feed href=https://www.evalapply.org/index.xml>Blog feed</a></span></nav><hr><form class=cluster action=https://buttondown.email/api/emails/embed-subscribe/evalapply method=post target=popupwindow onsubmit="window.open('https://buttondown.email/evalapply','popupwindow')"><span>Occasional newsletter</span>
<input type=email name=email id=bd-email>
<span><input type=submit value="Get the eval/apply dispatch">
<em>(thanks, <a href=https://buttondown.email target=_blank>Buttondown</a>!)</em></span></form></footer></article></main><footer id=site-footer><hr><div class="box invert footer stack"><p>&copy; 2023,
<a href=http://adityaathalye.com target=_blank>Aditya Athalye</a>.
<span>All content licensed
<a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0
</a>, except where noted otherwise.</span>
Built with
<a href=https://github.com/adityaathalye/shite>shite</a>.</div></footer><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "2a55df7e78f941c29a35207cedd0f66c"}'></script></div>